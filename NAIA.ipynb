{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b947229",
   "metadata": {},
   "source": [
    "## Imports and Database Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c4bf50",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from datetime import timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "conn = sqlite3.connect('room_data.db')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a850ca",
   "metadata": {},
   "source": [
    "## NAIA method for every room in room_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc7bece5",
   "metadata": {},
   "outputs": [],
   "source": [
    "room_ids = [1, 2, 3, 4, 6, 7, 8, 9, 20, 21, 27, 28, 29, 30, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 311, 51, 56, 57, 59, 60, 87, 88, 89, 90, 91, 92, 93, 94, 95, 104, 105, 115, 116, 117, 297, 261]\n",
    "\n",
    "for room_id in room_ids:\n",
    "    print(f\"\\n=== Processing room_id: {room_id} ===\")\n",
    "\n",
    "    query = f\"\"\"\n",
    "    SELECT room_id, timestamp, temperature, airquality, daylight, light\n",
    "    FROM sensor_data_history\n",
    "    WHERE room_id = {room_id}\n",
    "    ORDER BY timestamp ASC\n",
    "    \"\"\"\n",
    "    df = pd.read_sql_query(query, conn, parse_dates=['timestamp'])\n",
    "\n",
    "    if df.empty:\n",
    "        print(\"No data available.\")\n",
    "        continue\n",
    "\n",
    "    df = df.set_index('timestamp')\n",
    "    hourly = df.resample('1h').mean().dropna()\n",
    "    hourly['date'] = hourly.index.date\n",
    "    hourly['hour'] = hourly.index.hour\n",
    "\n",
    "    daily_patterns = hourly.pivot_table(\n",
    "        values='airquality',\n",
    "        index=['date', 'hour'],\n",
    "        aggfunc='mean'\n",
    "    ).unstack()\n",
    "    daily_patterns = daily_patterns.dropna()\n",
    "\n",
    "    if daily_patterns.empty:\n",
    "        print(\"Not enough hourly data.\")\n",
    "        continue\n",
    "\n",
    "    daily_patterns.columns = daily_patterns.columns.droplevel(0)\n",
    "    daily_patterns.index = pd.to_datetime(daily_patterns.index)\n",
    "\n",
    "    def iterative_clustering(data, initial_k=3, max_iters=5, var_threshold=0.5):\n",
    "        k = initial_k\n",
    "        X = data.values\n",
    "        for i in range(max_iters):\n",
    "            kmeans = KMeans(n_clusters=k, random_state=0).fit(X)\n",
    "            labels = kmeans.labels_\n",
    "            centers = kmeans.cluster_centers_\n",
    "            dispersions = []\n",
    "            for j in range(k):\n",
    "                cluster_points = X[labels == j]\n",
    "                dist = np.linalg.norm(cluster_points - centers[j], axis=1)\n",
    "                dispersions.append(dist.std())\n",
    "            worst = np.argmax(dispersions)\n",
    "            if dispersions[worst] < var_threshold:\n",
    "                break\n",
    "            k += 1\n",
    "        return KMeans(n_clusters=k, random_state=0).fit(data)\n",
    "\n",
    "    cluster_model = iterative_clustering(daily_patterns, initial_k=3)\n",
    "    labels = cluster_model.labels_\n",
    "    daily_patterns['cluster'] = labels\n",
    "\n",
    "    outlier_hours = []\n",
    "    for cluster in np.unique(labels):\n",
    "        cluster_data = daily_patterns[daily_patterns.cluster == cluster].iloc[:, :-1]\n",
    "        center = cluster_model.cluster_centers_[cluster]\n",
    "        dists = np.linalg.norm(cluster_data - center, axis=1)\n",
    "        Q1, Q3 = np.percentile(dists, [25, 75])\n",
    "        iqr = Q3 - Q1\n",
    "        lower, upper = Q1 - 1.5*iqr, Q3 + 1.5*iqr\n",
    "        mask = (dists < lower) | (dists > upper)\n",
    "        timestamps = cluster_data.index[mask]\n",
    "        outlier_hours.extend(timestamps)\n",
    "\n",
    "    print(\"Outlier hours:\", outlier_hours)\n",
    "\n",
    "    pca = PCA(n_components=2)\n",
    "    proj = pca.fit_transform(daily_patterns.iloc[:, :-1])\n",
    "    plt.figure(figsize=(8,6))\n",
    "    plt.scatter(proj[:,0], proj[:,1], c=labels, cmap='tab10', alpha=0.6)\n",
    "    for d in outlier_hours:\n",
    "        if d in daily_patterns.index:\n",
    "            idx = daily_patterns.index.get_loc(d)\n",
    "            plt.scatter(proj[idx,0], proj[idx,1], c='k', marker='x')\n",
    "    plt.title(f'Room {room_id}: Clustered Hourly Patterns with Outliers')\n",
    "    plt.xlabel('PC1')\n",
    "    plt.ylabel('PC2')\n",
    "    plt.show()\n",
    "\n",
    "    # Use the last day in the dataset\n",
    "    latest_ts = daily_patterns.index[-1]\n",
    "    row = daily_patterns.loc[latest_ts]\n",
    "    row_no_cluster = row.drop('cluster')\n",
    "    new_day = pd.DataFrame([row_no_cluster], index=[latest_ts])\n",
    "\n",
    "    def validate_new(patterns, cluster_model, data_with_labels):\n",
    "        results = {}\n",
    "        centers = cluster_model.cluster_centers_\n",
    "        radii = {}\n",
    "        for c in np.unique(data_with_labels.cluster):\n",
    "            pts = data_with_labels[data_with_labels.cluster == c].iloc[:, :-1].values\n",
    "            radii[c] = np.max(np.linalg.norm(pts - centers[c], axis=1))\n",
    "        regs = {}\n",
    "        for c in np.unique(data_with_labels.cluster):\n",
    "            subset = data_with_labels[data_with_labels.cluster == c]\n",
    "            X = np.arange(len(subset)).reshape(-1, 1)\n",
    "            y = subset.iloc[:, :-1].mean(axis=1).values\n",
    "            lr = LinearRegression().fit(X, y)\n",
    "            regs[c] = lr\n",
    "\n",
    "        for date, row in patterns.iterrows():\n",
    "            x_mean = row.mean()\n",
    "            dists = np.linalg.norm(centers - row.values, axis=1)\n",
    "            c = np.argmin(dists)\n",
    "            cond1 = dists[c] <= radii[c]\n",
    "            y_pred = regs[c].predict(np.array([[len(data_with_labels)]]))[0]\n",
    "            tol = 1.5 * np.std(data_with_labels[data_with_labels.cluster == c].iloc[:, :-1].mean(axis=1))\n",
    "            cond2 = abs(x_mean - y_pred) <= tol\n",
    "            results[date] = 'inlier' if cond1 and cond2 else 'outlier'\n",
    "        return results\n",
    "\n",
    "    validation_results = validate_new(new_day, cluster_model, daily_patterns)\n",
    "    print(\"Validation result for last day (Phase 2):\", validation_results)\n",
    "\n",
    "    # Store anomalies in the database\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute(\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS anomalies (\n",
    "            room_id INTEGER,\n",
    "            timestamp DATETIME,\n",
    "            temperature REAL,\n",
    "            airquality REAL,\n",
    "            daylight REAL,\n",
    "            light INTEGER,\n",
    "            source_model TEXT,\n",
    "            PRIMARY KEY (room_id, timestamp, source_model)\n",
    "        )\n",
    "    \"\"\")\n",
    "\n",
    "    for ts in outlier_hours:\n",
    "        ts_data = df.loc[df.index.floor('h') == ts]\n",
    "        for i, row_data in ts_data.iterrows():\n",
    "            cursor.execute(\"\"\"\n",
    "                INSERT OR IGNORE INTO anomalies (room_id, timestamp, temperature, airquality, daylight, light, source_model)\n",
    "                VALUES (?, ?, ?, ?, ?, ?, ?)\n",
    "            \"\"\", (\n",
    "                room_id,\n",
    "                i.isoformat(),\n",
    "                row_data.get('temperature'),\n",
    "                row_data.get('airquality'),\n",
    "                row_data.get('daylight'),\n",
    "                int(row_data.get('light')) if not pd.isna(row_data.get('light')) else None,\n",
    "                'NAIA'\n",
    "            ))\n",
    "\n",
    "    for val_ts, val_result in validation_results.items():\n",
    "        if val_result == 'outlier':\n",
    "            val_data = df.loc[df.index.floor('h') == val_ts]\n",
    "            for i, row_data in val_data.iterrows():\n",
    "                cursor.execute(\"\"\"\n",
    "                    INSERT OR IGNORE INTO anomalies (room_id, timestamp, temperature, airquality, daylight, light, source_model)\n",
    "                    VALUES (?, ?, ?, ?, ?, ?, ?)\n",
    "                \"\"\", (\n",
    "                    room_id,\n",
    "                    i.isoformat(),\n",
    "                    row_data.get('temperature'),\n",
    "                    row_data.get('airquality'),\n",
    "                    row_data.get('daylight'),\n",
    "                    int(row_data.get('light')) if not pd.isna(row_data.get('light')) else None,\n",
    "                    'NAIA'\n",
    "                ))\n",
    "\n",
    "    conn.commit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb3b30b0",
   "metadata": {},
   "source": [
    "## Additional visualization of the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12fb583",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load anomalies and sensor data\n",
    "anomalies_df = pd.read_sql_query(\"\"\"\n",
    "    SELECT * FROM anomalies\n",
    "    WHERE source_model = 'NAIA'\n",
    "\"\"\", conn, parse_dates=['timestamp'])\n",
    "\n",
    "last_day = new_day.index[0].date()\n",
    "last_day_data = df[df.index.date == last_day]\n",
    "last_day_data.loc[:, 'hour'] = last_day_data.index.hour\n",
    "last_day_data.loc[:, 'result'] = 'inlier'\n",
    "\n",
    "if list(validation_results.values())[0] == 'outlier':\n",
    "    last_day_data.loc[:, 'result'] = 'outlier'\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.countplot(data=last_day_data, x='result', hue='result', palette='Set2', legend=False)\n",
    "plt.title(f'Validation Outcome for Last Day ({last_day})')\n",
    "plt.xlabel('Result')\n",
    "plt.ylabel('Number of Records')\n",
    "plt.show()\n",
    "\n",
    "room_validation_summary = pd.DataFrame({\n",
    "    'room_id': [room_id],\n",
    "    'date': [last_day],\n",
    "    'result': list(validation_results.values())\n",
    "})\n",
    "print(\"Validation Outcome Summary\")\n",
    "display(room_validation_summary)\n",
    "\n",
    "\n",
    "anomaly_counts = anomalies_df.groupby('room_id').size().reset_index(name='outlier_count')\n",
    "plt.figure(figsize=(12, 5))\n",
    "sns.barplot(data=anomaly_counts, x='room_id', y='outlier_count', palette='crest')\n",
    "plt.title('Total Anomalies per Room (NAIA Model)')\n",
    "plt.xlabel('Room ID')\n",
    "plt.ylabel('Outlier Count')\n",
    "plt.xticks(rotation=90)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
